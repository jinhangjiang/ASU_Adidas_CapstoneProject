{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jinhang\n",
      "[nltk_data]     Jiang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Python program to generate word vectors using Word2Vec\n",
    "  \n",
    "# importing all necessary modules\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "  \n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "  \n",
    "# import basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# clean txt\n",
    "import string\n",
    "import re\n",
    "\n",
    "# cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinhang Jiang\\ASU - Adidas\n",
      "D:\\OneDrive\\ASU\\2021 Spring\\Applied Project\\ASU_Applied_Project_2021\\Text analytics\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())\n",
    "os.chdir('D:/OneDrive/ASU/2021 Spring/Applied Project/ASU_Applied_Project_2021/Text analytics')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = pd.read_csv(\"TextAnalytics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file1 = pd.read_csv(\"txt_data_full.csv\")\n",
    "#file2 = pd.read_csv(\"txt_data_korean.csv\")\n",
    "#file=pd.read_csv(\"txt_data_full.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view = file.groupby([\"Celebrity\",\"txt\"]).size().reset_index(name='Freq')\n",
    "view = file.groupby([\"Celebrity\",\"MsgBody\"]).size().reset_index(name='Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file1 = file1[file1[\"Celebrity\"]!='BlackPink']\n",
    "#file1 = file1[file1[\"Celebrity\"]!='Naeun Son']\n",
    "#file1.Celebrity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(file1)+len(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = pd.concat([file1,file2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file.to_csv(\"FullData.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AdrieneMishler', 'BadBunny', 'Beyonce', 'BlackPink',\n",
       "       'KarlieKloss', 'KerwinFrost', 'Naeun', 'NinjaHyper',\n",
       "       'PharrellWilliams', 'YaraShahidi', 'ZoeSaldana'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view.Celebrity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = ['Celebrity','txt']\n",
    "col = ['Celebrity','MsgBody']\n",
    "df = view[col]\n",
    "df.columns = ['Celebrity','txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celebrity    0\n",
       "txt          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"uniquesubredditdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BadBunny            971\n",
       "BlackPink           955\n",
       "Beyonce             929\n",
       "KarlieKloss         859\n",
       "NinjaHyper          829\n",
       "PharrellWilliams    462\n",
       "Naeun               428\n",
       "ZoeSaldana          279\n",
       "YaraShahidi         165\n",
       "KerwinFrost         149\n",
       "AdrieneMishler        4\n",
       "Name: Celebrity, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Celebrity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def text_preproc(x):\n",
    "  x = x.lower()\n",
    "  x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "  x = x.encode('ascii', 'ignore').decode()\n",
    "  x = re.sub(r'https*\\S+', ' ', x)\n",
    "  x = re.sub(r'@\\S+', ' ', x)\n",
    "  x = re.sub(r'#\\S+', ' ', x)\n",
    "  x = re.sub(r'\\'\\w+', '', x)\n",
    "  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "  x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "  x = re.sub(r'\\s{2,}', ' ', x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Clean_txt\"] = df.txt.apply(text_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_txt</th>\n",
       "      <th>clean txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Celebrity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdrieneMishler</th>\n",
       "      <td>[[ ,  lot intense expected im loving new serie...</td>\n",
       "      <td>[[ ,  lot intense expected im loving new serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BadBunny</th>\n",
       "      <td>[[ looks great really ,  remindme one week ,  ...</td>\n",
       "      <td>[[ looks great really ,  remindme one week ,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beyonce</th>\n",
       "      <td>[[ link info feedback savevideo dmca removal r...</td>\n",
       "      <td>[[ link info feedback savevideo dmca removal r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlackPink</th>\n",
       "      <td>[[ ros actually live vote inkigayo today short...</td>\n",
       "      <td>[[ ros actually live vote inkigayo today short...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KarlieKloss</th>\n",
       "      <td>[[ ,  ,  wow ,  post likely made spam bot spam...</td>\n",
       "      <td>[[ ,  ,  wow ,  post likely made spam bot spam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KerwinFrost</th>\n",
       "      <td>[[ dont know find hard believe lol ,  theory a...</td>\n",
       "      <td>[[ dont know find hard believe lol ,  theory a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naeun</th>\n",
       "      <td>[[ ,  ,  september issue gloomy day ,  clip al...</td>\n",
       "      <td>[[ ,  ,  september issue gloomy day ,  clip al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NinjaHyper</th>\n",
       "      <td>[[ virginity vrjind learn pronounce state neve...</td>\n",
       "      <td>[[ virginity vrjind learn pronounce state neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PharrellWilliams</th>\n",
       "      <td>[[ till morning mary j blige sooo rare ,  skat...</td>\n",
       "      <td>[[ till morning mary j blige sooo rare ,  skat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YaraShahidi</th>\n",
       "      <td>[[ would breed ,  ,  belly button though reall...</td>\n",
       "      <td>[[ would breed ,  ,  belly button though reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZoeSaldana</th>\n",
       "      <td>[[ for mobile non res users more info remove i...</td>\n",
       "      <td>[[ for mobile non res users more info remove i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Clean_txt  \\\n",
       "Celebrity                                                             \n",
       "AdrieneMishler    [[ ,  lot intense expected im loving new serie...   \n",
       "BadBunny          [[ looks great really ,  remindme one week ,  ...   \n",
       "Beyonce           [[ link info feedback savevideo dmca removal r...   \n",
       "BlackPink         [[ ros actually live vote inkigayo today short...   \n",
       "KarlieKloss       [[ ,  ,  wow ,  post likely made spam bot spam...   \n",
       "KerwinFrost       [[ dont know find hard believe lol ,  theory a...   \n",
       "Naeun             [[ ,  ,  september issue gloomy day ,  clip al...   \n",
       "NinjaHyper        [[ virginity vrjind learn pronounce state neve...   \n",
       "PharrellWilliams  [[ till morning mary j blige sooo rare ,  skat...   \n",
       "YaraShahidi       [[ would breed ,  ,  belly button though reall...   \n",
       "ZoeSaldana        [[ for mobile non res users more info remove i...   \n",
       "\n",
       "                                                          clean txt  \n",
       "Celebrity                                                            \n",
       "AdrieneMishler    [[ ,  lot intense expected im loving new serie...  \n",
       "BadBunny          [[ looks great really ,  remindme one week ,  ...  \n",
       "Beyonce           [[ link info feedback savevideo dmca removal r...  \n",
       "BlackPink         [[ ros actually live vote inkigayo today short...  \n",
       "KarlieKloss       [[ ,  ,  wow ,  post likely made spam bot spam...  \n",
       "KerwinFrost       [[ dont know find hard believe lol ,  theory a...  \n",
       "Naeun             [[ ,  ,  september issue gloomy day ,  clip al...  \n",
       "NinjaHyper        [[ virginity vrjind learn pronounce state neve...  \n",
       "PharrellWilliams  [[ till morning mary j blige sooo rare ,  skat...  \n",
       "YaraShahidi       [[ would breed ,  ,  belly button though reall...  \n",
       "ZoeSaldana        [[ for mobile non res users more info remove i...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df.groupby(['Celebrity'])['Clean_txt'].apply(list).groupby(level=0).apply(list)\n",
    "#df_merge = df.groupby(['Celebrity'])['txt'].apply(lambda x: '\\n'.join(x.astype(str))).reset_index()\n",
    "df_merge = pd.DataFrame(df_merge)\n",
    "df_merge[\"clean txt\"] = df_merge.Clean_txt.tolist()\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_merge.Clean_txt\n",
    "f = s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces escape character with space  \n",
    "data = []\n",
    "  \n",
    "# iterate through each sentence in the file\n",
    "for h in range(len(f)):\n",
    "    for i in sent_tokenize(str(f[h])):\n",
    "        temp = []\n",
    "        # tokenize the sentence into words\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j.lower())\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = word_tokenize(str(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Google Developers blog post says:\n",
    "\n",
    "Well, the following \"formula\" provides a general rule of thumb about the number of embedding dimensions:\n",
    "\n",
    "embedding_dimensions =  number_of_categories**0.25\n",
    "\n",
    "That is, the embedding vector dimension should be the 4th root of the number of categories.\n",
    "\n",
    "Interestingly, the Word2vec Wikipedia article says (emphasis mine):\n",
    "\n",
    "Nevertheless, for skip-gram models trained in medium size corpora, with 50 dimensions, a window size of 15 and 10 negative samples seems to be a good parameter setting.\n",
    "\n",
    "Assuming a standard-ish sized vocabulary of 1.5 million words, this rule of thumb comes surprisingly close:\n",
    "\n",
    "50 == 1.5e6 ** 0.2751"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328639"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(str(df_merge['clean txt'].tolist()))\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23.94306669'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_size = num_words**0.25\n",
    "\"{:.8f}\".format(float(dim_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(465751, 664420)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create skip-gram model\n",
    "model1 = gensim.models.Word2Vec(data, \n",
    "                                min_count = 1, \n",
    "                                size = 24, \n",
    "                                window = 15, \n",
    "                                negative= 5,\n",
    "                                sg=1)\n",
    "model1.train(data, total_examples=model1.corpus_count,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vectors = model1.wv.key_to_index, model1.wv.get_normed_vectors()\n",
    "\n",
    "# get node name and embedding vector index.\n",
    "name_index = np.array([(v[0], v[1]) for v in vocab.items()])\n",
    "\n",
    "# init dataframe using embedding vectors and set index as node name\n",
    "skip_gram =  pd.DataFrame(vectors[name_index[:,1].astype(int)])\n",
    "skip_gram.index = name_index[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vectors = model1.wv.vocab, model1.wv.vectors\n",
    "\n",
    "# get node name and embedding vector index.\n",
    "name_index = np.array([(v[0], v[1].index) for v in vocab.items()]) #.index\n",
    "\n",
    "# init dataframe using embedding vectors and set index as node name\n",
    "skip_gram =  pd.DataFrame(vectors[name_index[:,1].astype(int)])\n",
    "skip_gram.index = name_index[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[</th>\n",
       "      <td>0.448929</td>\n",
       "      <td>0.352467</td>\n",
       "      <td>-0.277827</td>\n",
       "      <td>-1.025365</td>\n",
       "      <td>-0.286233</td>\n",
       "      <td>0.313107</td>\n",
       "      <td>-1.011702</td>\n",
       "      <td>0.397680</td>\n",
       "      <td>-0.178801</td>\n",
       "      <td>-1.191547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.483522</td>\n",
       "      <td>-0.329058</td>\n",
       "      <td>-0.723705</td>\n",
       "      <td>-0.353244</td>\n",
       "      <td>-0.298426</td>\n",
       "      <td>0.077839</td>\n",
       "      <td>0.476473</td>\n",
       "      <td>0.413763</td>\n",
       "      <td>0.124413</td>\n",
       "      <td>0.050481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>0.309252</td>\n",
       "      <td>0.019247</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.066490</td>\n",
       "      <td>-0.237804</td>\n",
       "      <td>0.340768</td>\n",
       "      <td>-0.560672</td>\n",
       "      <td>0.770583</td>\n",
       "      <td>-0.120820</td>\n",
       "      <td>0.215736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.463441</td>\n",
       "      <td>-0.021508</td>\n",
       "      <td>-0.070747</td>\n",
       "      <td>-0.225182</td>\n",
       "      <td>-0.473421</td>\n",
       "      <td>-0.488701</td>\n",
       "      <td>0.368802</td>\n",
       "      <td>0.693047</td>\n",
       "      <td>-0.442766</td>\n",
       "      <td>0.151568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.271280</td>\n",
       "      <td>-0.019748</td>\n",
       "      <td>0.711261</td>\n",
       "      <td>0.078265</td>\n",
       "      <td>-0.222964</td>\n",
       "      <td>0.419945</td>\n",
       "      <td>-0.508146</td>\n",
       "      <td>0.858155</td>\n",
       "      <td>-0.155643</td>\n",
       "      <td>0.210081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443286</td>\n",
       "      <td>-0.098165</td>\n",
       "      <td>-0.107587</td>\n",
       "      <td>-0.239694</td>\n",
       "      <td>-0.397560</td>\n",
       "      <td>-0.431915</td>\n",
       "      <td>0.254447</td>\n",
       "      <td>0.740652</td>\n",
       "      <td>-0.434310</td>\n",
       "      <td>0.171679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>0.691905</td>\n",
       "      <td>0.186163</td>\n",
       "      <td>0.179255</td>\n",
       "      <td>-0.375637</td>\n",
       "      <td>-0.174451</td>\n",
       "      <td>-0.236841</td>\n",
       "      <td>-0.936031</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>-0.790878</td>\n",
       "      <td>0.466180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093743</td>\n",
       "      <td>-0.742182</td>\n",
       "      <td>0.453720</td>\n",
       "      <td>-0.744413</td>\n",
       "      <td>0.139190</td>\n",
       "      <td>-0.106973</td>\n",
       "      <td>-0.084066</td>\n",
       "      <td>0.140198</td>\n",
       "      <td>-0.359141</td>\n",
       "      <td>-0.486872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intense</th>\n",
       "      <td>0.163283</td>\n",
       "      <td>0.209086</td>\n",
       "      <td>0.071498</td>\n",
       "      <td>-0.269873</td>\n",
       "      <td>-0.300607</td>\n",
       "      <td>0.357290</td>\n",
       "      <td>-0.737919</td>\n",
       "      <td>-0.078279</td>\n",
       "      <td>-0.432388</td>\n",
       "      <td>0.312307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091036</td>\n",
       "      <td>-0.292140</td>\n",
       "      <td>0.149373</td>\n",
       "      <td>-0.230462</td>\n",
       "      <td>0.094319</td>\n",
       "      <td>-0.217423</td>\n",
       "      <td>0.151339</td>\n",
       "      <td>0.355185</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>-0.295085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geekboners</th>\n",
       "      <td>0.251129</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.152746</td>\n",
       "      <td>-0.139247</td>\n",
       "      <td>-0.093508</td>\n",
       "      <td>0.538443</td>\n",
       "      <td>-0.281336</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>-0.197836</td>\n",
       "      <td>-0.071337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179215</td>\n",
       "      <td>-0.094231</td>\n",
       "      <td>-0.065529</td>\n",
       "      <td>-0.191938</td>\n",
       "      <td>-0.581866</td>\n",
       "      <td>-0.417033</td>\n",
       "      <td>0.344111</td>\n",
       "      <td>0.721855</td>\n",
       "      <td>-0.295043</td>\n",
       "      <td>0.091944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ure</th>\n",
       "      <td>0.166506</td>\n",
       "      <td>0.245509</td>\n",
       "      <td>0.424546</td>\n",
       "      <td>-0.469263</td>\n",
       "      <td>0.105074</td>\n",
       "      <td>0.605109</td>\n",
       "      <td>-0.501088</td>\n",
       "      <td>0.558202</td>\n",
       "      <td>-0.560962</td>\n",
       "      <td>-0.017111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252148</td>\n",
       "      <td>-0.101439</td>\n",
       "      <td>-0.266395</td>\n",
       "      <td>-0.373530</td>\n",
       "      <td>-0.775347</td>\n",
       "      <td>-0.380534</td>\n",
       "      <td>0.389573</td>\n",
       "      <td>0.814459</td>\n",
       "      <td>-0.249236</td>\n",
       "      <td>0.078667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyu</th>\n",
       "      <td>0.131441</td>\n",
       "      <td>0.281625</td>\n",
       "      <td>0.274461</td>\n",
       "      <td>-0.231422</td>\n",
       "      <td>-0.056382</td>\n",
       "      <td>0.446756</td>\n",
       "      <td>-0.367384</td>\n",
       "      <td>0.402709</td>\n",
       "      <td>-0.454290</td>\n",
       "      <td>0.105018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198068</td>\n",
       "      <td>-0.199011</td>\n",
       "      <td>-0.092205</td>\n",
       "      <td>-0.308976</td>\n",
       "      <td>-0.503124</td>\n",
       "      <td>-0.296953</td>\n",
       "      <td>0.244564</td>\n",
       "      <td>0.690902</td>\n",
       "      <td>-0.202603</td>\n",
       "      <td>0.109299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dood</th>\n",
       "      <td>0.177851</td>\n",
       "      <td>0.281395</td>\n",
       "      <td>0.356482</td>\n",
       "      <td>-0.109070</td>\n",
       "      <td>-0.067447</td>\n",
       "      <td>0.421425</td>\n",
       "      <td>-0.244381</td>\n",
       "      <td>0.551277</td>\n",
       "      <td>-0.340765</td>\n",
       "      <td>0.238306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342369</td>\n",
       "      <td>-0.114313</td>\n",
       "      <td>0.080162</td>\n",
       "      <td>-0.334481</td>\n",
       "      <td>-0.416072</td>\n",
       "      <td>-0.206581</td>\n",
       "      <td>0.311295</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>-0.355574</td>\n",
       "      <td>0.146082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pizza</th>\n",
       "      <td>0.175103</td>\n",
       "      <td>-0.073151</td>\n",
       "      <td>0.351988</td>\n",
       "      <td>-0.258170</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>0.500786</td>\n",
       "      <td>-0.443415</td>\n",
       "      <td>0.680418</td>\n",
       "      <td>-0.393145</td>\n",
       "      <td>-0.145886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062871</td>\n",
       "      <td>-0.260047</td>\n",
       "      <td>-0.072451</td>\n",
       "      <td>-0.131057</td>\n",
       "      <td>-0.291468</td>\n",
       "      <td>-0.336879</td>\n",
       "      <td>0.447607</td>\n",
       "      <td>0.595901</td>\n",
       "      <td>-0.213246</td>\n",
       "      <td>0.085006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8787 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "[           0.448929  0.352467 -0.277827 -1.025365 -0.286233  0.313107   \n",
       "'           0.309252  0.019247  0.664373  0.066490 -0.237804  0.340768   \n",
       ",           0.271280 -0.019748  0.711261  0.078265 -0.222964  0.419945   \n",
       "lot         0.691905  0.186163  0.179255 -0.375637 -0.174451 -0.236841   \n",
       "intense     0.163283  0.209086  0.071498 -0.269873 -0.300607  0.357290   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "geekboners  0.251129  0.289463  0.152746 -0.139247 -0.093508  0.538443   \n",
       "ure         0.166506  0.245509  0.424546 -0.469263  0.105074  0.605109   \n",
       "oyu         0.131441  0.281625  0.274461 -0.231422 -0.056382  0.446756   \n",
       "dood        0.177851  0.281395  0.356482 -0.109070 -0.067447  0.421425   \n",
       "pizza       0.175103 -0.073151  0.351988 -0.258170  0.061982  0.500786   \n",
       "\n",
       "                  6         7         8         9   ...        14        15  \\\n",
       "[          -1.011702  0.397680 -0.178801 -1.191547  ... -0.483522 -0.329058   \n",
       "'          -0.560672  0.770583 -0.120820  0.215736  ... -0.463441 -0.021508   \n",
       ",          -0.508146  0.858155 -0.155643  0.210081  ... -0.443286 -0.098165   \n",
       "lot        -0.936031 -0.003984 -0.790878  0.466180  ... -0.093743 -0.742182   \n",
       "intense    -0.737919 -0.078279 -0.432388  0.312307  ... -0.091036 -0.292140   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "geekboners -0.281336  0.461496 -0.197836 -0.071337  ... -0.179215 -0.094231   \n",
       "ure        -0.501088  0.558202 -0.560962 -0.017111  ... -0.252148 -0.101439   \n",
       "oyu        -0.367384  0.402709 -0.454290  0.105018  ... -0.198068 -0.199011   \n",
       "dood       -0.244381  0.551277 -0.340765  0.238306  ... -0.342369 -0.114313   \n",
       "pizza      -0.443415  0.680418 -0.393145 -0.145886  ... -0.062871 -0.260047   \n",
       "\n",
       "                  16        17        18        19        20        21  \\\n",
       "[          -0.723705 -0.353244 -0.298426  0.077839  0.476473  0.413763   \n",
       "'          -0.070747 -0.225182 -0.473421 -0.488701  0.368802  0.693047   \n",
       ",          -0.107587 -0.239694 -0.397560 -0.431915  0.254447  0.740652   \n",
       "lot         0.453720 -0.744413  0.139190 -0.106973 -0.084066  0.140198   \n",
       "intense     0.149373 -0.230462  0.094319 -0.217423  0.151339  0.355185   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "geekboners -0.065529 -0.191938 -0.581866 -0.417033  0.344111  0.721855   \n",
       "ure        -0.266395 -0.373530 -0.775347 -0.380534  0.389573  0.814459   \n",
       "oyu        -0.092205 -0.308976 -0.503124 -0.296953  0.244564  0.690902   \n",
       "dood        0.080162 -0.334481 -0.416072 -0.206581  0.311295  0.681672   \n",
       "pizza      -0.072451 -0.131057 -0.291468 -0.336879  0.447607  0.595901   \n",
       "\n",
       "                  22        23  \n",
       "[           0.124413  0.050481  \n",
       "'          -0.442766  0.151568  \n",
       ",          -0.434310  0.171679  \n",
       "lot        -0.359141 -0.486872  \n",
       "intense     0.020076 -0.295085  \n",
       "...              ...       ...  \n",
       "geekboners -0.295043  0.091944  \n",
       "ure        -0.249236  0.078667  \n",
       "oyu        -0.202603  0.109299  \n",
       "dood       -0.355574  0.146082  \n",
       "pizza      -0.213246  0.085006  \n",
       "\n",
       "[8787 rows x 24 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70133483\n",
      "0.45662332\n",
      "0.21029365\n",
      "0.8811493\n",
      "0.6051391\n",
      "0.35325238\n"
     ]
    }
   ],
   "source": [
    "print(model1.wv.similarity('kpop','idol'))\n",
    "print(model1.wv.similarity('kpop','movie'))\n",
    "print(model1.wv.similarity('kpop','fortnite'))\n",
    "print(model1.wv.similarity('ninja','fortnite'))\n",
    "print(model1.wv.similarity('ninja','idol'))\n",
    "print(model1.wv.similarity('ninja','kpop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fortnite', 0.8811492919921875),\n",
       " ('minecraft', 0.8775534629821777),\n",
       " ('player', 0.869595468044281),\n",
       " ('facts', 0.8321744799613953),\n",
       " ('sellout', 0.8300344944000244),\n",
       " ('dumb', 0.8273787498474121),\n",
       " ('dis', 0.8273749351501465),\n",
       " ('gaming', 0.8243447542190552),\n",
       " ('blevins', 0.8234016299247742),\n",
       " ('mixer', 0.8189645409584045),\n",
       " ('stream', 0.8184990286827087),\n",
       " ('streak', 0.8113013505935669),\n",
       " ('twitch', 0.8102708458900452),\n",
       " ('himself', 0.8098055124282837),\n",
       " ('frick', 0.8041304349899292)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar('ninja',topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round # 1 for: AdrieneMishler started\n",
      "Round # 1 for: AdrieneMishler completed\n",
      "Round # 2 for: BadBunny started\n",
      "Round # 2 for: BadBunny completed\n",
      "Round # 3 for: Beyonce started\n",
      "Round # 3 for: Beyonce completed\n",
      "Round # 4 for: BlackPink started\n",
      "Round # 4 for: BlackPink completed\n",
      "Round # 5 for: KarlieKloss started\n",
      "Round # 5 for: KarlieKloss completed\n",
      "Round # 6 for: KerwinFrost started\n",
      "Round # 6 for: KerwinFrost completed\n",
      "Round # 7 for: Naeun started\n",
      "Round # 7 for: Naeun completed\n",
      "Round # 8 for: NinjaHyper started\n",
      "Round # 8 for: NinjaHyper completed\n",
      "Round # 9 for: PharrellWilliams started\n",
      "Round # 9 for: PharrellWilliams completed\n",
      "Round # 10 for: YaraShahidi started\n",
      "Round # 10 for: YaraShahidi completed\n",
      "Round # 11 for: ZoeSaldana started\n",
      "Round # 11 for: ZoeSaldana completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0:00:58.202160'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(data):\n",
    "    return \" \".join([str(item) for var in data for item in var])\n",
    "embedding = []\n",
    "embedding = pd.DataFrame(embedding)\n",
    "start = time.time()\n",
    "for i in range(len(df_merge.index)):\n",
    "    print('Round #',i+1,'for:',df_merge.index[i],\"started\")\n",
    "    temp_list = []\n",
    "    res = 0\n",
    "    temp_df = []\n",
    "    score = []\n",
    "    temp_list = pd.DataFrame(temp_list)\n",
    "    for j in word_tokenize(flatten(df_merge['clean txt'][i])):\n",
    "        if j in skip_gram.index:\n",
    "            try:\n",
    "                temp_list = temp_list.append(skip_gram.loc[[j]])\n",
    "            except:\n",
    "                pass\n",
    "    res = [temp_list.mean(axis=0)]\n",
    "    res = pd.DataFrame(res)\n",
    "    res.reset_index(drop=True, inplace=True)\n",
    "    temp_df = pd.Series(df_merge.index[i])\n",
    "    #temp_df.reset_index(drop=True, inplace=True)\n",
    "    score = pd.concat([temp_df, res], axis=1)\n",
    "    embedding = embedding.append(score)\n",
    "    print('Round #',i+1,'for:',df_merge.index[i],\"completed\")\n",
    "end = time.time()\n",
    "sec = end - start\n",
    "str(datetime.timedelta(seconds=sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celebrity</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdrieneMishler</td>\n",
       "      <td>0.310744</td>\n",
       "      <td>0.114894</td>\n",
       "      <td>0.372717</td>\n",
       "      <td>-0.208280</td>\n",
       "      <td>-0.290493</td>\n",
       "      <td>0.277001</td>\n",
       "      <td>-0.859835</td>\n",
       "      <td>0.364915</td>\n",
       "      <td>-0.406649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437173</td>\n",
       "      <td>-0.160311</td>\n",
       "      <td>0.236366</td>\n",
       "      <td>-0.228445</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>-0.019452</td>\n",
       "      <td>0.036492</td>\n",
       "      <td>0.394891</td>\n",
       "      <td>-0.101621</td>\n",
       "      <td>-0.199122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BadBunny</td>\n",
       "      <td>0.136958</td>\n",
       "      <td>0.674445</td>\n",
       "      <td>0.281728</td>\n",
       "      <td>0.049650</td>\n",
       "      <td>-0.211023</td>\n",
       "      <td>0.449171</td>\n",
       "      <td>-0.172975</td>\n",
       "      <td>0.523590</td>\n",
       "      <td>-0.355485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.413494</td>\n",
       "      <td>-0.498217</td>\n",
       "      <td>0.240107</td>\n",
       "      <td>-0.301446</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>-0.028627</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.711466</td>\n",
       "      <td>-0.004052</td>\n",
       "      <td>0.522069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyonce</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>0.264879</td>\n",
       "      <td>0.358117</td>\n",
       "      <td>-0.372402</td>\n",
       "      <td>-0.354545</td>\n",
       "      <td>0.326644</td>\n",
       "      <td>-0.584422</td>\n",
       "      <td>0.580935</td>\n",
       "      <td>-0.405819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288656</td>\n",
       "      <td>-0.077561</td>\n",
       "      <td>0.311651</td>\n",
       "      <td>-0.279049</td>\n",
       "      <td>-0.044278</td>\n",
       "      <td>-0.201773</td>\n",
       "      <td>-0.047545</td>\n",
       "      <td>0.493065</td>\n",
       "      <td>-0.204366</td>\n",
       "      <td>-0.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BlackPink</td>\n",
       "      <td>0.191954</td>\n",
       "      <td>0.089561</td>\n",
       "      <td>0.261991</td>\n",
       "      <td>-0.328939</td>\n",
       "      <td>-0.338810</td>\n",
       "      <td>0.142819</td>\n",
       "      <td>-0.558399</td>\n",
       "      <td>0.471002</td>\n",
       "      <td>-0.617489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274308</td>\n",
       "      <td>-0.249293</td>\n",
       "      <td>0.160287</td>\n",
       "      <td>-0.209325</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>-0.278825</td>\n",
       "      <td>0.111223</td>\n",
       "      <td>0.603437</td>\n",
       "      <td>-0.132365</td>\n",
       "      <td>-0.265872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KarlieKloss</td>\n",
       "      <td>0.191123</td>\n",
       "      <td>0.230257</td>\n",
       "      <td>0.390204</td>\n",
       "      <td>-0.198018</td>\n",
       "      <td>-0.404740</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>-0.387688</td>\n",
       "      <td>0.577787</td>\n",
       "      <td>-0.465359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379826</td>\n",
       "      <td>-0.109078</td>\n",
       "      <td>0.195172</td>\n",
       "      <td>-0.283731</td>\n",
       "      <td>-0.316237</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>0.156836</td>\n",
       "      <td>0.685766</td>\n",
       "      <td>-0.450535</td>\n",
       "      <td>-0.043631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KerwinFrost</td>\n",
       "      <td>0.094065</td>\n",
       "      <td>0.187953</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>-0.219476</td>\n",
       "      <td>-0.317549</td>\n",
       "      <td>0.410188</td>\n",
       "      <td>-0.554135</td>\n",
       "      <td>0.342787</td>\n",
       "      <td>-0.401288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089889</td>\n",
       "      <td>-0.216912</td>\n",
       "      <td>0.256140</td>\n",
       "      <td>-0.253167</td>\n",
       "      <td>-0.065108</td>\n",
       "      <td>-0.220009</td>\n",
       "      <td>0.015704</td>\n",
       "      <td>0.499282</td>\n",
       "      <td>-0.065472</td>\n",
       "      <td>-0.030220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naeun</td>\n",
       "      <td>0.152211</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>0.478240</td>\n",
       "      <td>-0.231692</td>\n",
       "      <td>-0.471472</td>\n",
       "      <td>0.229709</td>\n",
       "      <td>-0.536375</td>\n",
       "      <td>0.543151</td>\n",
       "      <td>-0.478449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256787</td>\n",
       "      <td>-0.317885</td>\n",
       "      <td>0.077743</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-0.320811</td>\n",
       "      <td>-0.445144</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.598740</td>\n",
       "      <td>-0.104608</td>\n",
       "      <td>-0.037189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NinjaHyper</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.139899</td>\n",
       "      <td>0.239689</td>\n",
       "      <td>-0.268080</td>\n",
       "      <td>-0.182330</td>\n",
       "      <td>0.414028</td>\n",
       "      <td>-0.593595</td>\n",
       "      <td>0.468796</td>\n",
       "      <td>-0.410481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185115</td>\n",
       "      <td>-0.176928</td>\n",
       "      <td>0.245693</td>\n",
       "      <td>-0.226624</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>-0.429991</td>\n",
       "      <td>0.090329</td>\n",
       "      <td>0.397031</td>\n",
       "      <td>-0.150313</td>\n",
       "      <td>-0.239926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PharrellWilliams</td>\n",
       "      <td>0.200032</td>\n",
       "      <td>0.197603</td>\n",
       "      <td>0.444601</td>\n",
       "      <td>-0.330970</td>\n",
       "      <td>-0.326325</td>\n",
       "      <td>0.247158</td>\n",
       "      <td>-0.595155</td>\n",
       "      <td>0.469113</td>\n",
       "      <td>-0.421571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269860</td>\n",
       "      <td>-0.163783</td>\n",
       "      <td>0.254522</td>\n",
       "      <td>-0.366641</td>\n",
       "      <td>-0.017411</td>\n",
       "      <td>-0.132049</td>\n",
       "      <td>-0.114197</td>\n",
       "      <td>0.442279</td>\n",
       "      <td>-0.228937</td>\n",
       "      <td>-0.039803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YaraShahidi</td>\n",
       "      <td>0.181733</td>\n",
       "      <td>0.070647</td>\n",
       "      <td>0.224475</td>\n",
       "      <td>-0.188440</td>\n",
       "      <td>-0.194939</td>\n",
       "      <td>0.471518</td>\n",
       "      <td>-0.444826</td>\n",
       "      <td>0.665451</td>\n",
       "      <td>-0.304680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418837</td>\n",
       "      <td>-0.138920</td>\n",
       "      <td>0.409053</td>\n",
       "      <td>-0.170414</td>\n",
       "      <td>-0.099778</td>\n",
       "      <td>-0.270859</td>\n",
       "      <td>-0.022407</td>\n",
       "      <td>0.471398</td>\n",
       "      <td>-0.149069</td>\n",
       "      <td>-0.255373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZoeSaldana</td>\n",
       "      <td>0.216118</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.168108</td>\n",
       "      <td>-0.293654</td>\n",
       "      <td>0.404948</td>\n",
       "      <td>-0.460739</td>\n",
       "      <td>0.560253</td>\n",
       "      <td>-0.415390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252289</td>\n",
       "      <td>-0.091780</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>-0.306180</td>\n",
       "      <td>-0.304844</td>\n",
       "      <td>-0.316401</td>\n",
       "      <td>0.155795</td>\n",
       "      <td>0.595101</td>\n",
       "      <td>-0.334028</td>\n",
       "      <td>-0.092412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Celebrity         1         2         3         4         5  \\\n",
       "0    AdrieneMishler  0.310744  0.114894  0.372717 -0.208280 -0.290493   \n",
       "0          BadBunny  0.136958  0.674445  0.281728  0.049650 -0.211023   \n",
       "0           Beyonce  0.059381  0.264879  0.358117 -0.372402 -0.354545   \n",
       "0         BlackPink  0.191954  0.089561  0.261991 -0.328939 -0.338810   \n",
       "0       KarlieKloss  0.191123  0.230257  0.390204 -0.198018 -0.404740   \n",
       "0       KerwinFrost  0.094065  0.187953  0.252109 -0.219476 -0.317549   \n",
       "0             Naeun  0.152211  0.147193  0.478240 -0.231692 -0.471472   \n",
       "0        NinjaHyper  0.002279  0.139899  0.239689 -0.268080 -0.182330   \n",
       "0  PharrellWilliams  0.200032  0.197603  0.444601 -0.330970 -0.326325   \n",
       "0       YaraShahidi  0.181733  0.070647  0.224475 -0.188440 -0.194939   \n",
       "0        ZoeSaldana  0.216118  0.175820  0.314748 -0.168108 -0.293654   \n",
       "\n",
       "          6         7         8         9  ...        15        16        17  \\\n",
       "0  0.277001 -0.859835  0.364915 -0.406649  ... -0.437173 -0.160311  0.236366   \n",
       "0  0.449171 -0.172975  0.523590 -0.355485  ... -0.413494 -0.498217  0.240107   \n",
       "0  0.326644 -0.584422  0.580935 -0.405819  ... -0.288656 -0.077561  0.311651   \n",
       "0  0.142819 -0.558399  0.471002 -0.617489  ... -0.274308 -0.249293  0.160287   \n",
       "0  0.339056 -0.387688  0.577787 -0.465359  ... -0.379826 -0.109078  0.195172   \n",
       "0  0.410188 -0.554135  0.342787 -0.401288  ... -0.089889 -0.216912  0.256140   \n",
       "0  0.229709 -0.536375  0.543151 -0.478449  ... -0.256787 -0.317885  0.077743   \n",
       "0  0.414028 -0.593595  0.468796 -0.410481  ... -0.185115 -0.176928  0.245693   \n",
       "0  0.247158 -0.595155  0.469113 -0.421571  ... -0.269860 -0.163783  0.254522   \n",
       "0  0.471518 -0.444826  0.665451 -0.304680  ... -0.418837 -0.138920  0.409053   \n",
       "0  0.404948 -0.460739  0.560253 -0.415390  ... -0.252289 -0.091780  0.166616   \n",
       "\n",
       "         18        19        20        21        22        23        24  \n",
       "0 -0.228445 -0.033324 -0.019452  0.036492  0.394891 -0.101621 -0.199122  \n",
       "0 -0.301446  0.023046 -0.028627  0.007682  0.711466 -0.004052  0.522069  \n",
       "0 -0.279049 -0.044278 -0.201773 -0.047545  0.493065 -0.204366 -0.127300  \n",
       "0 -0.209325  0.032408 -0.278825  0.111223  0.603437 -0.132365 -0.265872  \n",
       "0 -0.283731 -0.316237 -0.254614  0.156836  0.685766 -0.450535 -0.043631  \n",
       "0 -0.253167 -0.065108 -0.220009  0.015704  0.499282 -0.065472 -0.030220  \n",
       "0 -0.207339 -0.320811 -0.445144  0.151367  0.598740 -0.104608 -0.037189  \n",
       "0 -0.226624  0.066450 -0.429991  0.090329  0.397031 -0.150313 -0.239926  \n",
       "0 -0.366641 -0.017411 -0.132049 -0.114197  0.442279 -0.228937 -0.039803  \n",
       "0 -0.170414 -0.099778 -0.270859 -0.022407  0.471398 -0.149069 -0.255373  \n",
       "0 -0.306180 -0.304844 -0.316401  0.155795  0.595101 -0.334028 -0.092412  \n",
       "\n",
       "[11 rows x 25 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.columns=list(range(skip_gram.shape[1]+1))\n",
    "embedding.rename(columns={ embedding.columns[0]: \"Celebrity\" }, inplace = True)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding.to_csv(\"word2vec_embedding_V6_20.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(data,col,target,order = 'TopN'):\n",
    "    #default of parameter 'order' is equal to TopN, alternative is BotN\n",
    "    sim = []\n",
    "    for i in data[col]:\n",
    "        if i != target:\n",
    "            a = data[data[col]==target].drop(col,axis=1)\n",
    "            b = data[data[col]==i].drop(col,axis=1)\n",
    "            temp = (i,cosine_similarity(a,b))\n",
    "            sim.append(temp)\n",
    "    if order == 'TopN':\n",
    "        sim = sorted(sim, key=lambda t: t[1], reverse=True)\n",
    "    elif order == 'BotN':\n",
    "        sim = sorted(sim, key=lambda t: t[1], reverse=False)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZoeSaldana', array([[0.9510789]], dtype=float32)),\n",
       " ('KarlieKloss', array([[0.9388172]], dtype=float32)),\n",
       " ('BlackPink', array([[0.9197567]], dtype=float32)),\n",
       " ('KerwinFrost', array([[0.9133661]], dtype=float32)),\n",
       " ('Beyonce', array([[0.9089148]], dtype=float32)),\n",
       " ('PharrellWilliams', array([[0.8914171]], dtype=float32)),\n",
       " ('YaraShahidi', array([[0.8830012]], dtype=float32)),\n",
       " ('AdrieneMishler', array([[0.87815624]], dtype=float32)),\n",
       " ('NinjaHyper', array([[0.866635]], dtype=float32)),\n",
       " ('BadBunny', array([[0.721035]], dtype=float32))]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(embedding,'Celebrity','Naeun','TopN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PharrellWilliams', array([[0.97792125]], dtype=float32)),\n",
       " ('KerwinFrost', array([[0.95540553]], dtype=float32)),\n",
       " ('BlackPink', array([[0.94733673]], dtype=float32)),\n",
       " ('NinjaHyper', array([[0.93995535]], dtype=float32)),\n",
       " ('YaraShahidi', array([[0.93912035]], dtype=float32)),\n",
       " ('ZoeSaldana', array([[0.9364201]], dtype=float32)),\n",
       " ('KarlieKloss', array([[0.92646164]], dtype=float32)),\n",
       " ('AdrieneMishler', array([[0.9258249]], dtype=float32)),\n",
       " ('Naeun', array([[0.9089148]], dtype=float32)),\n",
       " ('BadBunny', array([[0.7626959]], dtype=float32))]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(embedding,'Celebrity','Beyonce','TopN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KerwinFrost', array([[0.94671685]], dtype=float32)),\n",
       " ('BlackPink', array([[0.94343036]], dtype=float32)),\n",
       " ('Beyonce', array([[0.93995535]], dtype=float32)),\n",
       " ('PharrellWilliams', array([[0.92128867]], dtype=float32)),\n",
       " ('YaraShahidi', array([[0.9194962]], dtype=float32)),\n",
       " ('ZoeSaldana', array([[0.9036615]], dtype=float32)),\n",
       " ('AdrieneMishler', array([[0.89098626]], dtype=float32)),\n",
       " ('Naeun', array([[0.866635]], dtype=float32)),\n",
       " ('KarlieKloss', array([[0.8648081]], dtype=float32)),\n",
       " ('BadBunny', array([[0.7125666]], dtype=float32))]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(embedding,'Celebrity','NinjaHyper','TopN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-trained Model from Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive\\ASU\\2021 Spring\\Applied Project\\ASU_Applied_Project_2021\\Model\n",
      "D:\\OneDrive\\ASU\\2021 Spring\\Applied Project\\ASU_Applied_Project_2021\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())\n",
    "os.chdir('D:/OneDrive/ASU/2021 Spring/Applied Project/ASU_Applied_Project_2021')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('./Model/GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vectors = model.wv.vocab, model.wv.vectors\n",
    "\n",
    "# get node name and embedding vector index.\n",
    "name_index = np.array([(v[0], v[1].index) for v in vocab.items()]) #.index\n",
    "\n",
    "# init dataframe using embedding vectors and set index as node name\n",
    "pretrain =  pd.DataFrame(vectors[name_index[:,1].astype(int)])\n",
    "pretrain.index = name_index[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>0.001129</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001549</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>-0.108887</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168945</td>\n",
       "      <td>-0.088867</td>\n",
       "      <td>-0.080566</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>-0.058838</td>\n",
       "      <td>-0.047607</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>-0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.011780</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>-0.063965</td>\n",
       "      <td>-0.001312</td>\n",
       "      <td>-0.072266</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022583</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>-0.082520</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>0.024170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.015747</td>\n",
       "      <td>-0.028320</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>-0.110352</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>-0.014221</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.033447</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>-0.019409</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>-0.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.007050</td>\n",
       "      <td>-0.073242</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>0.198242</td>\n",
       "      <td>0.112793</td>\n",
       "      <td>-0.107910</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.020874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233398</td>\n",
       "      <td>-0.036377</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>-0.024780</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.106934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAFFAELE</th>\n",
       "      <td>0.009277</td>\n",
       "      <td>-0.050537</td>\n",
       "      <td>-0.018799</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>-0.052490</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028076</td>\n",
       "      <td>-0.002853</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>-0.007385</td>\n",
       "      <td>-0.008606</td>\n",
       "      <td>-0.023560</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.026978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bim_Skala_Bim</th>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>-0.043213</td>\n",
       "      <td>-0.001495</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>-0.083496</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>-0.041504</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>-0.023315</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>-0.010620</td>\n",
       "      <td>-0.051514</td>\n",
       "      <td>-0.014282</td>\n",
       "      <td>0.051514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mezze_Cafe</th>\n",
       "      <td>-0.019653</td>\n",
       "      <td>-0.090820</td>\n",
       "      <td>-0.019409</td>\n",
       "      <td>0.019653</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.050293</td>\n",
       "      <td>-0.012695</td>\n",
       "      <td>0.024170</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046387</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.136719</td>\n",
       "      <td>-0.004547</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>0.046631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulverizes_boulders</th>\n",
       "      <td>0.032715</td>\n",
       "      <td>-0.032227</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>-0.084961</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>-0.070312</td>\n",
       "      <td>-0.167969</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>-0.007294</td>\n",
       "      <td>-0.009827</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.019043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowcapped_Caucasus</th>\n",
       "      <td>0.045166</td>\n",
       "      <td>-0.045166</td>\n",
       "      <td>-0.003937</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>-0.123535</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>-0.142578</td>\n",
       "      <td>-0.121094</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.100586</td>\n",
       "      <td>-0.062988</td>\n",
       "      <td>-0.113770</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>-0.041504</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1         2         3         4    \\\n",
       "</s>                 0.001129 -0.000896  0.000319  0.001534  0.001106   \n",
       "in                   0.070312  0.086914  0.087891  0.062500  0.069336   \n",
       "for                 -0.011780 -0.047363  0.044678  0.063477 -0.018188   \n",
       "that                -0.015747 -0.028320  0.083496  0.050293 -0.110352   \n",
       "is                   0.007050 -0.073242  0.171875  0.022583 -0.132812   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "RAFFAELE             0.009277 -0.050537 -0.018799  0.029785  0.037354   \n",
       "Bim_Skala_Bim        0.012573  0.045410 -0.043213 -0.001495  0.026489   \n",
       "Mezze_Cafe          -0.019653 -0.090820 -0.019409  0.019653 -0.000230   \n",
       "pulverizes_boulders  0.032715 -0.032227  0.036133  0.001175 -0.036621   \n",
       "snowcapped_Caucasus  0.045166 -0.045166 -0.003937  0.048828  0.088379   \n",
       "\n",
       "                          5         6         7         8         9    ...  \\\n",
       "</s>                -0.001404 -0.000031 -0.000420 -0.000576  0.001076  ...   \n",
       "in                  -0.108887 -0.081543 -0.154297  0.020752  0.131836  ...   \n",
       "for                 -0.063965 -0.001312 -0.072266  0.064453  0.086426  ...   \n",
       "that                 0.031738 -0.014221 -0.089844  0.117676  0.118164  ...   \n",
       "is                   0.198242  0.112793 -0.107910  0.071777  0.020874  ...   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "RAFFAELE             0.008911 -0.057617  0.035645 -0.052490  0.078125  ...   \n",
       "Bim_Skala_Bim        0.049561 -0.059326 -0.083496 -0.033691  0.099609  ...   \n",
       "Mezze_Cafe           0.040283 -0.050293 -0.012695  0.024170  0.013123  ...   \n",
       "pulverizes_boulders -0.084961  0.036865  0.032471  0.063477  0.114746  ...   \n",
       "snowcapped_Caucasus -0.123535 -0.033691 -0.142578 -0.121094  0.201172  ...   \n",
       "\n",
       "                          290       291       292       293       294  \\\n",
       "</s>                -0.001549  0.001373 -0.000061 -0.000824  0.001328   \n",
       "in                  -0.168945 -0.088867 -0.080566  0.064941  0.061279   \n",
       "for                 -0.022583  0.003723 -0.082520  0.081543  0.007935   \n",
       "that                -0.011292 -0.015625 -0.033447 -0.020630 -0.019409   \n",
       "is                  -0.233398 -0.036377 -0.093750  0.182617  0.027100   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "RAFFAELE            -0.028076 -0.002853 -0.059326 -0.007385 -0.008606   \n",
       "Bim_Skala_Bim        0.086914 -0.041504 -0.036865 -0.023315  0.012451   \n",
       "Mezze_Cafe          -0.046387  0.001076 -0.136719 -0.004547  0.022827   \n",
       "pulverizes_boulders  0.020020 -0.070312 -0.167969  0.003082 -0.060303   \n",
       "snowcapped_Caucasus  0.015991  0.100586 -0.062988 -0.113770  0.070801   \n",
       "\n",
       "                          295       296       297       298       299  \n",
       "</s>                 0.001160  0.000568 -0.001564 -0.000123 -0.000086  \n",
       "in                  -0.047363 -0.058838 -0.047607  0.014465 -0.062500  \n",
       "for                  0.000477  0.018433  0.071289 -0.034912  0.024170  \n",
       "that                 0.063965  0.020142  0.006866  0.061035 -0.148438  \n",
       "is                   0.127930 -0.024780  0.011230  0.164062  0.106934  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "RAFFAELE            -0.023560  0.016968 -0.012634  0.010620  0.026978  \n",
       "Bim_Skala_Bim       -0.112305 -0.010620 -0.051514 -0.014282  0.051514  \n",
       "Mezze_Cafe           0.042969 -0.046875 -0.016357 -0.013428  0.046631  \n",
       "pulverizes_boulders -0.007294 -0.009827 -0.008850  0.026978  0.019043  \n",
       "snowcapped_Caucasus -0.012939 -0.041504  0.079590  0.072266  0.013000  \n",
       "\n",
       "[3000000 rows x 300 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adidas', 0.8445298671722412),\n",
       " ('Nike', 0.7950947284698486),\n",
       " ('Adidas_ADDDY.PK_news', 0.6852840185165405),\n",
       " ('Reebok', 0.6841334104537964),\n",
       " ('Puma', 0.6774643659591675),\n",
       " ('Adidas_Salomon', 0.659113883972168),\n",
       " ('spokesman_Jan_Runau', 0.6242237091064453),\n",
       " ('adidas_Salomon_AG', 0.6223492622375488),\n",
       " ('sportswear', 0.614206075668335),\n",
       " ('Adidas_Salomon_AG', 0.6134569048881531),\n",
       " ('Umbro', 0.6109203696250916),\n",
       " ('Nike_Adidas', 0.6075664758682251),\n",
       " ('Adidas_Nike', 0.6061606407165527),\n",
       " ('Adidas_Reebok', 0.6059699058532715),\n",
       " ('Adidas_AG', 0.6053416132926941)]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Adidas',topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round # 1 for: Adriene Mishler started\n",
      "Round # 1 for: Adriene Mishler completed\n",
      "Round # 2 for: Ally Love started\n",
      "Round # 2 for: Ally Love completed\n",
      "Round # 3 for: BTS started\n",
      "Round # 3 for: BTS completed\n",
      "Round # 4 for: Bad Bunny started\n",
      "Round # 4 for: Bad Bunny completed\n",
      "Round # 5 for: Beyonce started\n",
      "Round # 5 for: Beyonce completed\n",
      "Round # 6 for: BlackPink started\n",
      "Round # 6 for: BlackPink completed\n",
      "Round # 7 for: Chinae Alexander started\n",
      "Round # 7 for: Chinae Alexander completed\n",
      "Round # 8 for: GFriend started\n",
      "Round # 8 for: GFriend completed\n",
      "Round # 9 for: Jerry Lorenzo started\n",
      "Round # 9 for: Jerry Lorenzo completed\n",
      "Round # 10 for: Karlie Kloss started\n",
      "Round # 10 for: Karlie Kloss completed\n",
      "Round # 11 for: Kerwin Frost started\n",
      "Round # 11 for: Kerwin Frost completed\n",
      "Round # 12 for: NCT started\n",
      "Round # 12 for: NCT completed\n",
      "Round # 13 for: Naeun Son started\n",
      "Round # 13 for: Naeun Son completed\n",
      "Round # 14 for: Ninjas Hyper started\n",
      "Round # 14 for: Ninjas Hyper completed\n",
      "Round # 15 for: Pharrell Williams started\n",
      "Round # 15 for: Pharrell Williams completed\n",
      "Round # 16 for: Seolhyun started\n",
      "Round # 16 for: Seolhyun completed\n",
      "Round # 17 for: Solar started\n",
      "Round # 17 for: Solar completed\n",
      "Round # 18 for: Yara Shahidi started\n",
      "Round # 18 for: Yara Shahidi completed\n",
      "Round # 19 for: Zoe Saldana started\n",
      "Round # 19 for: Zoe Saldana completed\n",
      "Round # 20 for: iZone started\n",
      "Round # 20 for: iZone completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3:47:53.287497'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(data):\n",
    "    return \" \".join([str(item) for var in data for item in var])\n",
    "embedding1 = []\n",
    "embedding1 = pd.DataFrame(embedding1)\n",
    "start = time.time()\n",
    "for i in range(len(df_merge.index)):\n",
    "    print('Round #',i+1,'for:',df_merge.index[i],\"started\")\n",
    "    temp_list = []\n",
    "    res = 0\n",
    "    temp_df = []\n",
    "    score = []\n",
    "    temp_list = pd.DataFrame(temp_list)\n",
    "    for j in word_tokenize(flatten(df_merge['clean txt'][i])):\n",
    "        if j in pretrain.index:\n",
    "            try:\n",
    "                temp_list = temp_list.append(pretrain.loc[[j]])\n",
    "            except:\n",
    "                pass\n",
    "    res = [temp_list.mean(axis=0)]\n",
    "    res = pd.DataFrame(res)\n",
    "    res.reset_index(drop=True, inplace=True)\n",
    "    temp_df = pd.Series(df_merge.index[i])\n",
    "    #temp_df.reset_index(drop=True, inplace=True)\n",
    "    score = pd.concat([temp_df, res], axis=1)\n",
    "    embedding1 = embedding1.append(score)\n",
    "    print('Round #',i+1,'for:',df_merge.index[i],\"completed\")\n",
    "end = time.time()\n",
    "sec = end - start\n",
    "str(datetime.timedelta(seconds=sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celebrity</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adriene Mishler</td>\n",
       "      <td>0.019793</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>0.122618</td>\n",
       "      <td>-0.088852</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>-0.067733</td>\n",
       "      <td>0.042789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031978</td>\n",
       "      <td>0.066720</td>\n",
       "      <td>-0.075106</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>-0.055297</td>\n",
       "      <td>-0.081830</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>-0.064345</td>\n",
       "      <td>0.040174</td>\n",
       "      <td>-0.035986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ally Love</td>\n",
       "      <td>0.037586</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.101464</td>\n",
       "      <td>-0.050598</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>-0.081055</td>\n",
       "      <td>0.066994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048690</td>\n",
       "      <td>0.056643</td>\n",
       "      <td>-0.097944</td>\n",
       "      <td>0.012078</td>\n",
       "      <td>-0.035606</td>\n",
       "      <td>-0.038087</td>\n",
       "      <td>0.015601</td>\n",
       "      <td>-0.056402</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>-0.002797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTS</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.041555</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>-0.052766</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>-0.084883</td>\n",
       "      <td>0.068388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033710</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>-0.088663</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>-0.036776</td>\n",
       "      <td>-0.054573</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>-0.063648</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>0.027914</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.023155</td>\n",
       "      <td>0.108129</td>\n",
       "      <td>-0.060856</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>-0.068683</td>\n",
       "      <td>0.077053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029898</td>\n",
       "      <td>0.065523</td>\n",
       "      <td>-0.090585</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>-0.040830</td>\n",
       "      <td>-0.042112</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>-0.064537</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyonce</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.096273</td>\n",
       "      <td>-0.056763</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>-0.083845</td>\n",
       "      <td>0.070861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024841</td>\n",
       "      <td>0.064021</td>\n",
       "      <td>-0.099711</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>-0.038623</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>0.017023</td>\n",
       "      <td>-0.067449</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.004472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BlackPink</td>\n",
       "      <td>0.027150</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.093344</td>\n",
       "      <td>-0.065385</td>\n",
       "      <td>0.013252</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>-0.078235</td>\n",
       "      <td>0.071041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027220</td>\n",
       "      <td>0.060017</td>\n",
       "      <td>-0.080311</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>-0.024289</td>\n",
       "      <td>-0.049553</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.076731</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>-0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinae Alexander</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.049290</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.097467</td>\n",
       "      <td>-0.063927</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>-0.084250</td>\n",
       "      <td>0.073489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063513</td>\n",
       "      <td>0.041224</td>\n",
       "      <td>-0.080961</td>\n",
       "      <td>0.031402</td>\n",
       "      <td>-0.030553</td>\n",
       "      <td>-0.024027</td>\n",
       "      <td>-0.011215</td>\n",
       "      <td>-0.055705</td>\n",
       "      <td>0.022407</td>\n",
       "      <td>0.003045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GFriend</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>0.040091</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.096585</td>\n",
       "      <td>-0.060128</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>-0.078769</td>\n",
       "      <td>0.075016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033719</td>\n",
       "      <td>0.056597</td>\n",
       "      <td>-0.086717</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>-0.035836</td>\n",
       "      <td>-0.051766</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>-0.061709</td>\n",
       "      <td>-0.001846</td>\n",
       "      <td>0.009795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jerry Lorenzo</td>\n",
       "      <td>0.021244</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.101443</td>\n",
       "      <td>-0.052247</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.026838</td>\n",
       "      <td>-0.084881</td>\n",
       "      <td>0.071702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029382</td>\n",
       "      <td>0.057926</td>\n",
       "      <td>-0.079298</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>-0.018837</td>\n",
       "      <td>-0.042945</td>\n",
       "      <td>0.013146</td>\n",
       "      <td>-0.077336</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karlie Kloss</td>\n",
       "      <td>0.028763</td>\n",
       "      <td>0.027666</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.086401</td>\n",
       "      <td>-0.064500</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.043514</td>\n",
       "      <td>-0.079579</td>\n",
       "      <td>0.077085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029916</td>\n",
       "      <td>0.049216</td>\n",
       "      <td>-0.085180</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>-0.023550</td>\n",
       "      <td>-0.044988</td>\n",
       "      <td>0.031553</td>\n",
       "      <td>-0.085584</td>\n",
       "      <td>-0.011459</td>\n",
       "      <td>-0.004492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kerwin Frost</td>\n",
       "      <td>0.033136</td>\n",
       "      <td>0.029836</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.099230</td>\n",
       "      <td>-0.053800</td>\n",
       "      <td>0.016219</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>-0.079157</td>\n",
       "      <td>0.085669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020109</td>\n",
       "      <td>0.060301</td>\n",
       "      <td>-0.093554</td>\n",
       "      <td>0.021721</td>\n",
       "      <td>-0.048473</td>\n",
       "      <td>-0.058359</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>-0.072278</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT</td>\n",
       "      <td>0.026302</td>\n",
       "      <td>0.042415</td>\n",
       "      <td>0.018434</td>\n",
       "      <td>0.093169</td>\n",
       "      <td>-0.053579</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.039680</td>\n",
       "      <td>-0.078607</td>\n",
       "      <td>0.074423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037322</td>\n",
       "      <td>0.059348</td>\n",
       "      <td>-0.081673</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>-0.035465</td>\n",
       "      <td>-0.042945</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>-0.066017</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naeun Son</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.046561</td>\n",
       "      <td>0.016199</td>\n",
       "      <td>0.091725</td>\n",
       "      <td>-0.049425</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>0.038033</td>\n",
       "      <td>-0.073237</td>\n",
       "      <td>0.068812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037776</td>\n",
       "      <td>0.055131</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>-0.033665</td>\n",
       "      <td>-0.045581</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>-0.064526</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.005956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ninjas Hyper</td>\n",
       "      <td>0.055860</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.015307</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>-0.050704</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>-0.072546</td>\n",
       "      <td>0.073966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>0.054093</td>\n",
       "      <td>-0.087158</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>-0.031361</td>\n",
       "      <td>-0.037533</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>-0.060230</td>\n",
       "      <td>-0.006420</td>\n",
       "      <td>0.006117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pharrell Williams</td>\n",
       "      <td>0.025635</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.094560</td>\n",
       "      <td>-0.050893</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>-0.093418</td>\n",
       "      <td>0.067716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025028</td>\n",
       "      <td>0.064214</td>\n",
       "      <td>-0.088041</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>-0.032199</td>\n",
       "      <td>-0.060254</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>-0.078084</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.007859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seolhyun</td>\n",
       "      <td>0.036171</td>\n",
       "      <td>0.050432</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>0.093516</td>\n",
       "      <td>-0.054053</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.046891</td>\n",
       "      <td>-0.077533</td>\n",
       "      <td>0.074835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043493</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>-0.083078</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>-0.035095</td>\n",
       "      <td>-0.054513</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>-0.073001</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.008996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>0.040452</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.082575</td>\n",
       "      <td>-0.059028</td>\n",
       "      <td>-0.001607</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>-0.080575</td>\n",
       "      <td>0.077642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035465</td>\n",
       "      <td>0.052690</td>\n",
       "      <td>-0.083209</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>-0.032558</td>\n",
       "      <td>-0.049387</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>-0.059347</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>-0.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yara Shahidi</td>\n",
       "      <td>0.030923</td>\n",
       "      <td>0.040545</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>-0.063182</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.037113</td>\n",
       "      <td>-0.076189</td>\n",
       "      <td>0.069485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040496</td>\n",
       "      <td>0.057241</td>\n",
       "      <td>-0.082158</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>-0.033227</td>\n",
       "      <td>-0.053204</td>\n",
       "      <td>0.026758</td>\n",
       "      <td>-0.074647</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.003244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Saldana</td>\n",
       "      <td>0.033443</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>-0.058779</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>-0.083942</td>\n",
       "      <td>0.070189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027309</td>\n",
       "      <td>0.064132</td>\n",
       "      <td>-0.099699</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>-0.037944</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>0.018501</td>\n",
       "      <td>-0.066872</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.003797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iZone</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.048160</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.091235</td>\n",
       "      <td>-0.053612</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>-0.077936</td>\n",
       "      <td>0.071595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036291</td>\n",
       "      <td>0.054487</td>\n",
       "      <td>-0.082389</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>-0.050271</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>-0.065486</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.009855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Celebrity         1         2         3         4         5  \\\n",
       "0    Adriene Mishler  0.019793  0.020356 -0.009257  0.122618 -0.088852   \n",
       "0          Ally Love  0.037586  0.032016  0.010924  0.101464 -0.050598   \n",
       "0                BTS  0.033026  0.041555  0.010861  0.098711 -0.052766   \n",
       "0          Bad Bunny  0.027914  0.025996  0.023155  0.108129 -0.060856   \n",
       "0            Beyonce  0.032351  0.023312  0.009082  0.096273 -0.056763   \n",
       "0          BlackPink  0.027150  0.032800  0.011482  0.093344 -0.065385   \n",
       "0   Chinae Alexander  0.008082  0.049290  0.020450  0.097467 -0.063927   \n",
       "0            GFriend  0.027004  0.040091  0.016053  0.096585 -0.060128   \n",
       "0      Jerry Lorenzo  0.021244  0.042060  0.008501  0.101443 -0.052247   \n",
       "0       Karlie Kloss  0.028763  0.027666  0.018322  0.086401 -0.064500   \n",
       "0       Kerwin Frost  0.033136  0.029836  0.020959  0.099230 -0.053800   \n",
       "0                NCT  0.026302  0.042415  0.018434  0.093169 -0.053579   \n",
       "0          Naeun Son  0.021906  0.046561  0.016199  0.091725 -0.049425   \n",
       "0       Ninjas Hyper  0.055860  0.045408  0.015307  0.090959 -0.050704   \n",
       "0  Pharrell Williams  0.025635  0.031562  0.016279  0.094560 -0.050893   \n",
       "0           Seolhyun  0.036171  0.050432  0.015498  0.093516 -0.054053   \n",
       "0              Solar  0.029036  0.040452  0.017840  0.082575 -0.059028   \n",
       "0       Yara Shahidi  0.030923  0.040545  0.013365  0.094296 -0.063182   \n",
       "0        Zoe Saldana  0.033443  0.023349  0.008512  0.095855 -0.058779   \n",
       "0              iZone  0.030801  0.048160  0.019175  0.091235 -0.053612   \n",
       "\n",
       "          6         7         8         9  ...       291       292       293  \\\n",
       "0  0.024864  0.005068 -0.067733  0.042789  ... -0.031978  0.066720 -0.075106   \n",
       "0  0.004588  0.039665 -0.081055  0.066994  ... -0.048690  0.056643 -0.097944   \n",
       "0  0.005887  0.037012 -0.084883  0.068388  ... -0.033710  0.048913 -0.088663   \n",
       "0  0.019012  0.036342 -0.068683  0.077053  ... -0.029898  0.065523 -0.090585   \n",
       "0  0.008562  0.030702 -0.083845  0.070861  ... -0.024841  0.064021 -0.099711   \n",
       "0  0.013252  0.040367 -0.078235  0.071041  ... -0.027220  0.060017 -0.080311   \n",
       "0  0.000798  0.034737 -0.084250  0.073489  ... -0.063513  0.041224 -0.080961   \n",
       "0  0.009476  0.040476 -0.078769  0.075016  ... -0.033719  0.056597 -0.086717   \n",
       "0  0.001172  0.026838 -0.084881  0.071702  ... -0.029382  0.057926 -0.079298   \n",
       "0  0.008643  0.043514 -0.079579  0.077085  ... -0.029916  0.049216 -0.085180   \n",
       "0  0.016219  0.034174 -0.079157  0.085669  ... -0.020109  0.060301 -0.093554   \n",
       "0  0.003052  0.039680 -0.078607  0.074423  ... -0.037322  0.059348 -0.081673   \n",
       "0  0.006477  0.038033 -0.073237  0.068812  ... -0.037776  0.055131 -0.080281   \n",
       "0  0.019324  0.036549 -0.072546  0.073966  ... -0.040431  0.054093 -0.087158   \n",
       "0  0.002898  0.026774 -0.093418  0.067716  ... -0.025028  0.064214 -0.088041   \n",
       "0  0.010892  0.046891 -0.077533  0.074835  ... -0.043493  0.045533 -0.083078   \n",
       "0 -0.001607  0.040762 -0.080575  0.077642  ... -0.035465  0.052690 -0.083209   \n",
       "0  0.010676  0.037113 -0.076189  0.069485  ... -0.040496  0.057241 -0.082158   \n",
       "0  0.008444  0.031357 -0.083942  0.070189  ... -0.027309  0.064132 -0.099699   \n",
       "0  0.003385  0.037963 -0.077936  0.071595  ... -0.036291  0.054487 -0.082389   \n",
       "\n",
       "        294       295       296       297       298       299       300  \n",
       "0  0.026110 -0.055297 -0.081830 -0.000275 -0.064345  0.040174 -0.035986  \n",
       "0  0.012078 -0.035606 -0.038087  0.015601 -0.056402  0.006107 -0.002797  \n",
       "0  0.004390 -0.036776 -0.054573  0.005194 -0.063648  0.002218  0.008100  \n",
       "0  0.017268 -0.040830 -0.042112  0.008867 -0.064537 -0.003894  0.006629  \n",
       "0  0.008088 -0.038623 -0.047189  0.017023 -0.067449  0.001485  0.004472  \n",
       "0  0.005647 -0.024289 -0.049553  0.018443 -0.076731 -0.000560 -0.002266  \n",
       "0  0.031402 -0.030553 -0.024027 -0.011215 -0.055705  0.022407  0.003045  \n",
       "0  0.006659 -0.035836 -0.051766  0.005225 -0.061709 -0.001846  0.009795  \n",
       "0  0.019005 -0.018837 -0.042945  0.013146 -0.077336 -0.000441  0.001909  \n",
       "0  0.015062 -0.023550 -0.044988  0.031553 -0.085584 -0.011459 -0.004492  \n",
       "0  0.021721 -0.048473 -0.058359  0.008858 -0.072278 -0.000208  0.002104  \n",
       "0  0.007607 -0.035465 -0.042945  0.002947 -0.066017  0.003801  0.004432  \n",
       "0  0.009721 -0.033665 -0.045581 -0.003565 -0.064526  0.006730  0.005956  \n",
       "0  0.009535 -0.031361 -0.037533  0.005904 -0.060230 -0.006420  0.006117  \n",
       "0  0.006073 -0.032199 -0.060254  0.019163 -0.078084 -0.000192  0.007859  \n",
       "0  0.006830 -0.035095 -0.054513  0.002955 -0.073001  0.008047  0.008996  \n",
       "0  0.007864 -0.032558 -0.049387  0.005073 -0.059347  0.007658 -0.000360  \n",
       "0  0.013789 -0.033227 -0.053204  0.026758 -0.074647  0.001526 -0.003244  \n",
       "0  0.006754 -0.037944 -0.045078  0.018501 -0.066872  0.002723  0.003797  \n",
       "0  0.003176 -0.036804 -0.050271 -0.002287 -0.065486  0.006312  0.009855  \n",
       "\n",
       "[20 rows x 301 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1.columns=list(range(pretrain.shape[1]+1))\n",
    "embedding1.rename(columns={embedding1.columns[0]: \"Celebrity\" }, inplace = True)\n",
    "embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding1.to_csv(\"./Data/word2vec_embedding_pretrain1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iZone', array([[0.9967277]], dtype=float32)),\n",
       " ('NCT', array([[0.9953402]], dtype=float32))]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(embedding1,'Celebrity','Naeun Son','TopN')[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zoe Saldana', array([[0.9997813]], dtype=float32)),\n",
       " ('BlackPink', array([[0.98949885]], dtype=float32))]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(embedding1,'Celebrity','Beyonce','TopN')[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ally Love', array([[0.98195165]], dtype=float32)),\n",
       " ('NCT', array([[0.9788385]], dtype=float32))]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(embedding1,'Celebrity','Ninjas Hyper','TopN')[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
